{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.677Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 1: Libraries**","metadata":{}},{"cell_type":"code","source":"# Step 1: Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:22:34.976500Z","iopub.execute_input":"2025-05-01T14:22:34.977242Z","iopub.status.idle":"2025-05-01T14:22:39.535445Z","shell.execute_reply.started":"2025-05-01T14:22:34.977200Z","shell.execute_reply":"2025-05-01T14:22:39.534013Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# **Step 2: Data Loading**","metadata":{}},{"cell_type":"code","source":"# Step 2: Load the data\ntrain = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:22:44.116369Z","iopub.execute_input":"2025-05-01T14:22:44.116687Z","iopub.status.idle":"2025-05-01T14:22:49.689343Z","shell.execute_reply.started":"2025-05-01T14:22:44.116666Z","shell.execute_reply":"2025-05-01T14:22:49.688201Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# **Step 3: Check the Dataset**","metadata":{}},{"cell_type":"code","source":"# Step 3: See the data\nprint(train.shape)\nprint(test.shape)\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:22:51.639316Z","iopub.execute_input":"2025-05-01T14:22:51.639639Z","iopub.status.idle":"2025-05-01T14:22:51.680277Z","shell.execute_reply.started":"2025-05-01T14:22:51.639618Z","shell.execute_reply":"2025-05-01T14:22:51.679023Z"}},"outputs":[{"name":"stdout","text":"(42000, 785)\n(28000, 784)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# **Visualize a Digit**","metadata":{}},{"cell_type":"code","source":"# Pick a random digit\ndigit = train.iloc[0, 1:].values\ndigit = digit.reshape(28,28)\n\nplt.imshow(digit, cmap='gray')\nplt.title(f\"Label: {train.iloc[0, 0]}\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:22:53.376588Z","iopub.execute_input":"2025-05-01T14:22:53.376872Z","iopub.status.idle":"2025-05-01T14:22:53.670976Z","shell.execute_reply.started":"2025-05-01T14:22:53.376852Z","shell.execute_reply":"2025-05-01T14:22:53.669948Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# **Step 4: Prepare X and Y**","metadata":{}},{"cell_type":"code","source":"# Step 4: Prepare X and y\nX = train.drop('label', axis=1)\ny = train['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:22:58.146777Z","iopub.execute_input":"2025-05-01T14:22:58.147107Z","iopub.status.idle":"2025-05-01T14:22:58.268597Z","shell.execute_reply.started":"2025-05-01T14:22:58.147084Z","shell.execute_reply":"2025-05-01T14:22:58.267423Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# **Step 5: Normalize the pixel Values**","metadata":{}},{"cell_type":"code","source":"# Step 5: Normalize the pixel values\nX = X / 255.0\ntest_norm = test / 255.0  # Also normalize the test set\ntest.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:22:59.426031Z","iopub.execute_input":"2025-05-01T14:22:59.427569Z","iopub.status.idle":"2025-05-01T14:22:59.561030Z","shell.execute_reply.started":"2025-05-01T14:22:59.427501Z","shell.execute_reply":"2025-05-01T14:22:59.559700Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n4       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 784 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# **Step 6: Train/Validation Split**","metadata":{}},{"cell_type":"code","source":"# Step 6: Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:23:02.914454Z","iopub.execute_input":"2025-05-01T14:23:02.914824Z","iopub.status.idle":"2025-05-01T14:23:03.177400Z","shell.execute_reply.started":"2025-05-01T14:23:02.914796Z","shell.execute_reply":"2025-05-01T14:23:03.176208Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# **Model 1: Logistic Regression**","metadata":{}},{"cell_type":"code","source":"# model_log = LogisticRegression(max_iter=1000)\n# model_log.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.679Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Check Model Accuracy on Validation Set**","metadata":{}},{"cell_type":"code","source":"# # Predict on validation set\n# y_pred = model_log.predict(X_val)\n\n# # Calculate accuracy\n# accuracy_log = accuracy_score(y_val, y_pred)\n# print(f\"Validation Accuracy: {accuracy_log * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.680Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Predict on the test data\n# test_predictions = model_log.predict(test)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.680Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model 2: K-Nearest Neighbors (KNN)**","metadata":{}},{"cell_type":"code","source":"# # Build KNN model\n# model_knn = KNeighborsClassifier(n_neighbors=3)  # You can tune k=3,5,7 etc\n# model_knn.fit(X_train, y_train)\n\n# # Predict and evaluate\n# y_pred_knn = model_knn.predict(X_val)\n# accuracy_knn = accuracy_score(y_val, y_pred_knn)\n# print(f\"KNN Validation Accuracy: {accuracy_knn * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.680Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model 3: Random Forest Classifier**","metadata":{}},{"cell_type":"code","source":"# # Build Random Forest model\n# model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n# model_rf.fit(X_train, y_train)\n\n# # Predict and evaluate\n# y_pred_rf = model_rf.predict(X_val)\n# accuracy_rf = accuracy_score(y_val, y_pred_rf)\n# print(f\"Random Forest Validation Accuracy: {accuracy_rf * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.681Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model 4: Simple Neural Network (MLPClassifier)**","metadata":{}},{"cell_type":"code","source":"# from sklearn.neural_network import MLPClassifier\n\n# # Build MLP model\n# model_mlp = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=20, alpha=1e-4,\n#                           solver='adam', verbose=10, random_state=1)\n\n# model_mlp.fit(X_train, y_train)\n\n# # Predict and evaluate\n# y_pred_mlp = model_mlp.predict(X_val)\n# accuracy_mlp = accuracy_score(y_val, y_pred_mlp)\n# print(f\"MLP Neural Network Validation Accuracy: {accuracy_mlp * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.681Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Keras MLP**","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# import tensorflow as tf\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n# from sklearn.model_selection import train_test_split\n\n# # Build MLP model\n# model = Sequential([\n#     Dense(512, activation='relu', input_shape=(784,)),\n#     BatchNormalization(),\n#     Dropout(0.3),\n\n#     Dense(256, activation='relu'),\n#     BatchNormalization(),\n#     Dropout(0.3),\n\n#     Dense(128, activation='relu'),\n#     BatchNormalization(),\n#     Dropout(0.3),\n\n#     Dense(10, activation='softmax')\n# ])\n\n# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# # Callbacks\n# early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n# reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2)\n\n# # Train\n# history = model.fit(X_train, y_train, epochs=40, batch_size=128,\n#                     validation_data=(X_val, y_val),\n#                     callbacks=[early_stop, reduce_lr])\n\n# # Evaluate\n# val_loss, val_acc = model.evaluate(X_val, y_val)\n# print(f'Validation Accuracy: {val_acc:.4f}')\n\n# # Predict and prepare submission\n# predictions = model.predict(test)\n# predicted_labels = np.argmax(predictions, axis=1)\n\n# submission = pd.DataFrame({\n#     'ImageId': np.arange(1, len(predicted_labels)+1),\n#     'Label': predicted_labels\n# })\n# submission.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:13:34.920233Z","iopub.execute_input":"2025-05-01T14:13:34.920623Z","iopub.status.idle":"2025-05-01T14:15:19.286943Z","shell.execute_reply.started":"2025-05-01T14:13:34.920595Z","shell.execute_reply":"2025-05-01T14:15:19.285930Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.7849 - loss: 0.7042 - val_accuracy: 0.9515 - val_loss: 0.1752 - learning_rate: 0.0010\nEpoch 2/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9414 - loss: 0.1908 - val_accuracy: 0.9643 - val_loss: 0.1152 - learning_rate: 0.0010\nEpoch 3/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9566 - loss: 0.1419 - val_accuracy: 0.9701 - val_loss: 0.1021 - learning_rate: 0.0010\nEpoch 4/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9655 - loss: 0.1057 - val_accuracy: 0.9698 - val_loss: 0.1000 - learning_rate: 0.0010\nEpoch 5/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9710 - loss: 0.0902 - val_accuracy: 0.9744 - val_loss: 0.0833 - learning_rate: 0.0010\nEpoch 6/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9751 - loss: 0.0771 - val_accuracy: 0.9736 - val_loss: 0.0811 - learning_rate: 0.0010\nEpoch 7/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9775 - loss: 0.0685 - val_accuracy: 0.9733 - val_loss: 0.0889 - learning_rate: 0.0010\nEpoch 8/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9827 - loss: 0.0539 - val_accuracy: 0.9787 - val_loss: 0.0694 - learning_rate: 5.0000e-04\nEpoch 9/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9877 - loss: 0.0375 - val_accuracy: 0.9785 - val_loss: 0.0709 - learning_rate: 5.0000e-04\nEpoch 10/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9893 - loss: 0.0342 - val_accuracy: 0.9767 - val_loss: 0.0759 - learning_rate: 5.0000e-04\nEpoch 11/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9905 - loss: 0.0285 - val_accuracy: 0.9788 - val_loss: 0.0692 - learning_rate: 2.5000e-04\nEpoch 12/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9927 - loss: 0.0232 - val_accuracy: 0.9792 - val_loss: 0.0706 - learning_rate: 2.5000e-04\nEpoch 13/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9929 - loss: 0.0231 - val_accuracy: 0.9805 - val_loss: 0.0711 - learning_rate: 2.5000e-04\nEpoch 14/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9946 - loss: 0.0164 - val_accuracy: 0.9800 - val_loss: 0.0734 - learning_rate: 2.5000e-04\nEpoch 15/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9945 - loss: 0.0176 - val_accuracy: 0.9795 - val_loss: 0.0745 - learning_rate: 2.5000e-04\nEpoch 16/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9947 - loss: 0.0155 - val_accuracy: 0.9802 - val_loss: 0.0718 - learning_rate: 1.2500e-04\nEpoch 17/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9962 - loss: 0.0140 - val_accuracy: 0.9810 - val_loss: 0.0726 - learning_rate: 1.2500e-04\nEpoch 18/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9964 - loss: 0.0114 - val_accuracy: 0.9804 - val_loss: 0.0728 - learning_rate: 1.2500e-04\nEpoch 19/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9966 - loss: 0.0111 - val_accuracy: 0.9813 - val_loss: 0.0728 - learning_rate: 1.2500e-04\nEpoch 20/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9967 - loss: 0.0113 - val_accuracy: 0.9806 - val_loss: 0.0739 - learning_rate: 1.2500e-04\nEpoch 21/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9964 - loss: 0.0109 - val_accuracy: 0.9810 - val_loss: 0.0747 - learning_rate: 1.2500e-04\nEpoch 22/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9970 - loss: 0.0099 - val_accuracy: 0.9810 - val_loss: 0.0753 - learning_rate: 6.2500e-05\nEpoch 23/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9978 - loss: 0.0086 - val_accuracy: 0.9812 - val_loss: 0.0752 - learning_rate: 6.2500e-05\nEpoch 24/40\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9972 - loss: 0.0085 - val_accuracy: 0.9808 - val_loss: 0.0749 - learning_rate: 3.1250e-05\n\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.0798\nValidation Accuracy: 0.9813\n\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# **Ensemble Code (3 MLP Models)**","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# import tensorflow as tf\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n# from sklearn.model_selection import train_test_split\n\n# # Common callbacks\n# early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n# reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2)\n\n# # Function to create a model (can vary structure slightly)\n# def create_mlp_model(seed=1, layer_sizes=[512, 256, 128]):\n#     tf.random.set_seed(seed)\n#     model = Sequential()\n#     model.add(Dense(layer_sizes[0], activation='relu', input_shape=(784,)))\n#     model.add(BatchNormalization())\n#     model.add(Dropout(0.3))\n    \n#     model.add(Dense(layer_sizes[1], activation='relu'))\n#     model.add(BatchNormalization())\n#     model.add(Dropout(0.3))\n    \n#     model.add(Dense(layer_sizes[2], activation='relu'))\n#     model.add(BatchNormalization())\n#     model.add(Dropout(0.3))\n\n#     model.add(Dense(10, activation='softmax'))\n#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n#     return model\n\n# # List of models to train\n# model_configs = [\n#     {\"seed\": 1, \"layers\": [512, 256, 128]},\n#     {\"seed\": 2, \"layers\": [512, 256, 64]},\n#     {\"seed\": 3, \"layers\": [256, 128, 64]}\n# ]\n\n# test_preds = []\n\n# for config in model_configs:\n#     print(f\"Training model with seed {config['seed']} and layers {config['layers']}\")\n#     model = create_mlp_model(seed=config['seed'], layer_sizes=config['layers'])\n    \n#     model.fit(X_train, y_train, epochs=40, batch_size=128,\n#               validation_data=(X_val, y_val),\n#               callbacks=[early_stop, reduce_lr],\n#               verbose=0)\n    \n#     # Predict probabilities on test set\n#     pred = model.predict(test.values, verbose=0)\n#     test_preds.append(pred)\n\n# # Average predictions\n# ensemble_pred = np.mean(test_preds, axis=0)\n# final_labels = np.argmax(ensemble_pred, axis=1)\n\n# # Create submission\n# submission = pd.DataFrame({\n#     'ImageId': np.arange(1, len(final_labels) + 1),\n#     'Label': final_labels\n# })\n# submission.to_csv('submission.csv', index=False)\n# print(\"✅ Submission saved as ensemble_submission.csv\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.682Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Improving**","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# import tensorflow as tf\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n# from sklearn.model_selection import train_test_split\n\n\n# # Common callbacks\n# early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n# reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2)\n\n# # Function to create the strong MLP model\n# def create_mlp_model(seed):\n#     tf.random.set_seed(seed)\n#     model = Sequential([\n#         Dense(512, activation='relu', input_shape=(784,)),\n#         BatchNormalization(),\n#         Dropout(0.3),\n\n#         Dense(256, activation='relu'),\n#         BatchNormalization(),\n#         Dropout(0.3),\n\n#         Dense(128, activation='relu'),\n#         BatchNormalization(),\n#         Dropout(0.3),\n\n#         Dense(10, activation='softmax')\n#     ])\n#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n#     return model\n\n# # Train 3 identical models with different seeds\n# seeds = [1, 2, 3]\n# test_preds = []\n\n# for seed in seeds:\n#     print(f\"Training model with seed {seed}\")\n#     model = create_mlp_model(seed)\n    \n#     model.fit(X_train, y_train, epochs=40, batch_size=128,\n#               validation_data=(X_val, y_val),\n#               callbacks=[early_stop, reduce_lr],\n#               verbose=0)\n    \n#     pred = model.predict(test.values, verbose=0)\n#     test_preds.append(pred)\n\n# # Average predictions\n# ensemble_pred = np.mean(test_preds, axis=0)\n# final_labels = np.argmax(ensemble_pred, axis=1)\n\n# # Create submission\n# submission = pd.DataFrame({\n#     'ImageId': np.arange(1, len(final_labels) + 1),\n#     'Label': final_labels\n# })\n# submission.to_csv('submission.csv', index=False)\n# print(\"✅ Submission saved as ensemble_submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:05:05.903200Z","iopub.execute_input":"2025-05-01T14:05:05.903963Z","iopub.status.idle":"2025-05-01T14:07:37.637907Z","shell.execute_reply.started":"2025-05-01T14:05:05.903934Z","shell.execute_reply":"2025-05-01T14:07:37.636924Z"}},"outputs":[{"name":"stdout","text":"Training model with seed 1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Training model with seed 2\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Training model with seed 3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"✅ Submission saved as ensemble_submission.csv\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n\n\n# Callbacks\nearly_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2)\n\n# Define the MLP model\ndef create_mlp_model(seed=1):\n    tf.random.set_seed(seed)\n    model = Sequential([\n        Dense(512, activation='relu', input_shape=(784,)),\n        BatchNormalization(),\n        Dropout(0.3),\n        Dense(256, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.3),\n        Dense(128, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.3),\n        Dense(10, activation='softmax')\n    ])\n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Step 1: Train original model\nmodel = create_mlp_model()\nmodel.fit(X_train, y_train, epochs=40, batch_size=128,\n          validation_data=(X_val, y_val),\n          callbacks=[early_stop, reduce_lr],\n          verbose=0)\n\n# Step 2: Predict on test set\ntest_probs = model.predict(test_norm.values, verbose=0)\npseudo_labels = np.argmax(test_probs, axis=1)\nconfidence = np.max(test_probs, axis=1)\n\n# Step 3: Keep only high-confidence predictions\nthreshold = 0.99\nhigh_confidence_idx = np.where(confidence >= threshold)[0]\nX_pseudo = test_norm.iloc[high_confidence_idx]\ny_pseudo = pseudo_labels[high_confidence_idx]\n\nprint(f\"Pseudo-labeling {len(X_pseudo)} high-confidence test samples\")\n\n# Step 4: Combine pseudo-labeled test data with original training data\nX_new = pd.concat([X, X_pseudo], axis=0)\ny_new = pd.concat([y, pd.Series(y_pseudo)], axis=0)\n\n# Step 5: Retrain model on full + pseudo-labeled data\nX_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_new, y_new, test_size=0.1, random_state=42)\n\nmodel_final = create_mlp_model()\nmodel_final.fit(X_train_final, y_train_final, epochs=40, batch_size=128,\n                validation_data=(X_val_final, y_val_final),\n                callbacks=[early_stop, reduce_lr],\n                verbose=0)\n\n# Step 6: Predict final submission\nfinal_probs = model_final.predict(test_norm.values, verbose=0)\nfinal_preds = np.argmax(final_probs, axis=1)\n\n# Save submission\nsubmission = pd.DataFrame({\n    'ImageId': np.arange(1, len(final_preds) + 1),\n    'Label': final_preds\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"✅ Submission saved as submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:23:35.533606Z","iopub.execute_input":"2025-05-01T14:23:35.533978Z","iopub.status.idle":"2025-05-01T14:26:18.007721Z","shell.execute_reply.started":"2025-05-01T14:23:35.533951Z","shell.execute_reply":"2025-05-01T14:26:18.006896Z"}},"outputs":[{"name":"stderr","text":"2025-05-01 14:23:37.952333: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746109418.227947      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746109418.304169      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n2025-05-01 14:23:54.547481: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"name":"stdout","text":"Pseudo-labeling 26665 high-confidence test samples\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"✅ Submission saved as submission.csv\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# **Model 5: Voting Classifier**","metadata":{}},{"cell_type":"code","source":"# from sklearn.ensemble import VotingClassifier\n\n# # Create an ensemble\n# ensemble = VotingClassifier(estimators=[\n#     ('lr', model_log),\n#     ('knn', model_knn),\n#     ('rf', model_rf)\n# ], voting='hard')\n\n# # Train ensemble\n# ensemble.fit(X_train, y_train)\n\n# # Predict and evaluate\n# y_pred_ensemble = ensemble.predict(X_val)\n# accuracy_ensemble = accuracy_score(y_val, y_pred_ensemble)\n# print(f\"Ensemble Validation Accuracy: {accuracy_ensemble * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.683Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Compare all models**","metadata":{}},{"cell_type":"code","source":"# print(f\"Logistic Regression Accuracy: {accuracy_log * 100:.2f}%\")\n# print(f\"KNN Accuracy: {accuracy_knn * 100:.2f}%\")\n# print(f\"Random Forest Accuracy: {accuracy_rf * 100:.2f}%\")\n# print(f\"MLP Neural Network Accuracy: {accuracy_mlp * 100:.2f}%\")\n# print(f\"Voting Classifier Accuracy: {accuracy_ensemble * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.683Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Save**","metadata":{}},{"cell_type":"code","source":"# # Predict on the test set\n# final_predictions = model_mlp.predict(test)\n\n# # Create submission file\n# submission = pd.DataFrame({\n#     \"ImageId\": list(range(1, len(final_predictions)+1)),\n#     \"Label\": final_predictions\n# })\n\n# submission.to_csv(\"submission.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.683Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model 6: Convolutional Neural Networks (CNNs)**","metadata":{}},{"cell_type":"markdown","source":"# **Another CNN Training**","metadata":{}},{"cell_type":"code","source":"# # Reshape input to be [samples][width][height][channels]\n# X_train = X_train.values.reshape(-1, 28, 28, 1)\n# X_val = X_val.values.reshape(-1, 28, 28, 1)\n# test = test.values.reshape(-1, 28, 28, 1)\n\n# import tensorflow as tf\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\n# model = Sequential()\n\n# # Layer 1: Convolutional + ReLU activation\n# model.add(Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n# # Layer 2: Pooling\n# model.add(MaxPooling2D((2,2)))\n\n# # Layer 3: Convolutional\n# model.add(Conv2D(64, (3,3), activation='relu'))\n# # Layer 4: Pooling\n# model.add(MaxPooling2D((2,2)))\n\n# # Layer 5: Flatten the 2D data\n# model.add(Flatten())\n\n# # Layer 6: Fully connected layer\n# model.add(Dense(128, activation='relu'))\n\n# # Layer 7: Dropout (helps avoid overfitting)\n# model.add(Dropout(0.5))\n\n# # Layer 8: Output layer (10 digits: 0 to 9)\n# model.add(Dense(10, activation='softmax'))\n\n# model.compile(optimizer='adam',\n#               loss='sparse_categorical_crossentropy',\n#               metrics=['accuracy'])\n\n# history = model.fit(X_train, y_train, epochs=10,\n#                     validation_data=(X_val, y_val),\n#                     batch_size=64)\n\n# val_loss, val_acc = model.evaluate(X_val, y_val)\n# print(f\"Validation Accuracy: {val_acc:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# predictions = model.predict(test)\n# predicted_labels = np.argmax(predictions, axis=1)\n\n# # Prepare CSV for submission\n# submission = pd.DataFrame({\n#     'ImageId': np.arange(1, len(predicted_labels)+1),\n#     'Label': predicted_labels\n# })\n# submission.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Step 1: Import libraries\n# import numpy as np\n# import pandas as pd\n# import matplotlib.pyplot as plt\n\n# # TensorFlow and Keras\n# import tensorflow as tf\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# # Step 2: Load the data\n# train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n# test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n\n# # Step 3: Prepare X and y\n# X = train.drop('label', axis=1) / 255.0\n# y = train['label']\n# test = test / 255.0\n\n# # Step 4: Reshape data for CNN\n# X = X.values.reshape(-1, 28, 28, 1)\n# test = test.values.reshape(-1, 28, 28, 1)\n\n# # Step 5: Split into training and validation\n# from sklearn.model_selection import train_test_split\n# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n\n# # Step 6: Data Augmentation\n# datagen = ImageDataGenerator(\n#     rotation_range=10,\n#     zoom_range=0.1,\n#     width_shift_range=0.1,\n#     height_shift_range=0.1\n# )\n# datagen.fit(X_train)\n\n# # Step 7: Build the CNN model\n# model = Sequential()\n\n# # Block 1\n# model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(28,28,1)))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(2,2))\n# model.add(Dropout(0.25))\n\n# # Block 2\n# model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(2,2))\n# model.add(Dropout(0.25))\n\n# # Fully connected layers\n# model.add(Flatten())\n# model.add(Dense(256, activation='relu'))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.5))\n# model.add(Dense(10, activation='softmax'))\n\n# # Step 8: Compile the model\n# model.compile(optimizer='adam',\n#               loss='sparse_categorical_crossentropy',\n#               metrics=['accuracy'])\n\n# # Step 9: Callbacks\n# early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n# lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2)\n\n# # Step 10: Train the model\n# history = model.fit(datagen.flow(X_train, y_train, batch_size=64),\n#                     epochs=40,\n#                     validation_data=(X_val, y_val),\n#                     steps_per_epoch=len(X_train) // 64,\n#                     callbacks=[early_stop, lr_scheduler])\n\n# # Step 11: Evaluate on validation set\n# val_loss, val_acc = model.evaluate(X_val, y_val)\n# print(f'Validation Accuracy: {val_acc:.4f}')\n\n# # Step 12: Predict on test set\n# predictions = model.predict(test)\n# predicted_labels = np.argmax(predictions, axis=1)\n\n# # Step 13: Create submission file\n# submission = pd.DataFrame({\n#     'ImageId': np.arange(1, len(predicted_labels) + 1),\n#     'Label': predicted_labels\n# })\n# submission.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-01T13:59:40.684Z"}},"outputs":[],"execution_count":null}]}